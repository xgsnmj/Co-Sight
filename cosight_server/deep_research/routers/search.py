# Copyright 2025 ZTE Corporation.
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

import json
import asyncio
import os
from datetime import datetime
from pathlib import Path
from typing import Any
from fastapi import APIRouter, Body
from starlette.requests import Request
from fastapi.responses import StreamingResponse
from urllib.parse import quote
from app.cosight.task.task_manager import TaskManager
from llm import llm_for_plan, llm_for_act, llm_for_tool, llm_for_vision
from cosight_server.deep_research.services.i18n_service import i18n
from cosight_server.deep_research.services.credibility_analyzer import credibility_analyzer
from app.common.logger_util import logger

# å¼•å…¥CoSightæ‰€éœ€çš„ä¾èµ–
from app.cosight.task.plan_report_manager import plan_report_event_manager
from app.cosight.task.todolist import Plan
from CoSight import CoSight

searchRouter = APIRouter()

# ä½¿ç”¨ä»ç¯å¢ƒå˜é‡è·å–çš„WORKSPACE_PATH
work_space_path = os.environ.get('WORKSPACE_PATH')
work_space_path = os.path.join(work_space_path, "work_space") if work_space_path else os.path.join(os.getcwd(), "work_space")
logger.info(f"Using work_space_path: {work_space_path}")
if not os.path.exists(work_space_path):
    os.makedirs(work_space_path)

# ç¡®ä¿logsç›®å½•å­˜åœ¨
LOGS_PATH = os.path.join(work_space_path, 'plans')
if not os.path.exists(LOGS_PATH):
    os.makedirs(LOGS_PATH)


# å°†æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºå¯è¢«å‰ç«¯è®¿é—®çš„URL
def _file_path_to_url(path_value: str) -> str:
    try:
        if not isinstance(path_value, str) or len(path_value) == 0:
            return path_value

        # æ ‡å‡†åŒ–åˆ†éš”ç¬¦ï¼Œä¾¿äºæŸ¥æ‰¾
        normalized = path_value.replace("\\", "/")

        # åªå…³å¿ƒ work_space ä¹‹åçš„ç›¸å¯¹è·¯å¾„
        marker = "work_space/"
        idx = normalized.find(marker)
        if idx == -1:
            return path_value

        relative = normalized[idx:]  # å½¢å¦‚ work_space/work_space_2025.../xxx.md

        # è¯»å–åç«¯é…ç½®ä¸­çš„åŸºç¡€ API å‰ç¼€
        try:
            from cosight_server.sdk.common.config import custom_config
            base_url = str(custom_config.get("base_api_url"))
        except Exception:
            # å¦‚æœé…ç½®æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é»˜è®¤å€¼
            base_url = "/api/nae-deep-research/v1"

        # å¯¹æ–‡ä»¶åè¿›è¡ŒURLç¼–ç ï¼Œç¡®ä¿ä¸­æ–‡å­—ç¬¦æ­£ç¡®å¤„ç†
        parts = relative.split("/")
        if len(parts) >= 2:

            relative = "/".join(parts)

        return f"{base_url}/{relative}"
    except Exception:
        return path_value


def _rewrite_paths_in_payload(payload):
    """é€’å½’éå†å¯¹è±¡ï¼Œå°†åŒ…å« work_space çš„æœ¬åœ°è·¯å¾„æ›¿æ¢ä¸º URLã€‚"""
    try:
        if isinstance(payload, dict):
            new_obj = {}
            for k, v in payload.items():
                # é’ˆå¯¹æ–‡ä»¶æ“ä½œäº‹ä»¶ç»“æ„è¿›è¡Œç‰¹æ®Šå¤„ç†
                if k == "file_path" and isinstance(v, str):
                    new_obj[k] = _file_path_to_url(v)
                else:
                    new_obj[k] = _rewrite_paths_in_payload(v)
            return new_obj
        elif isinstance(payload, list):
            return [_rewrite_paths_in_payload(item) for item in payload]
        elif isinstance(payload, str):
            # å°è¯•æŠŠ JSON å­—ç¬¦ä¸²è§£å‡ºæ¥å†å¤„ç†
            try:
                obj = json.loads(payload)
                return json.dumps(_rewrite_paths_in_payload(obj), ensure_ascii=False)
            except Exception:
                return _file_path_to_url(payload)
        else:
            return payload
    except Exception:
        return payload

async def _trigger_credibility_analysis(plan_queue, plan_data: Plan, completed_step: str):
    """è§¦å‘å¯ä¿¡åˆ†æ - å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹"""
    
    # ç«‹å³æ£€æŸ¥å¹¶ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥éª¤ï¼Œä¸ç­‰å¾…å¯ä¿¡åˆ†æ
    await _check_and_continue_next_step(plan_queue, plan_data)
    
    # å¼‚æ­¥æ‰§è¡Œå¯ä¿¡åˆ†æï¼Œä¸é˜»å¡ä¸»æµç¨‹
    try:
        logger.info(f"å‡†å¤‡åˆ›å»ºå¯ä¿¡åˆ†æä»»åŠ¡: {completed_step}")
        task = asyncio.create_task(_async_credibility_analysis(plan_queue, plan_data, completed_step))
        logger.info(f"å¯ä¿¡åˆ†æä»»åŠ¡å·²åˆ›å»º: {completed_step}")
    except Exception as e:
        logger.error(f"åˆ›å»ºå¯ä¿¡åˆ†æä»»åŠ¡å¤±è´¥: {e}", exc_info=True)

async def _async_credibility_analysis(plan_queue, plan_data: Plan, completed_step: str):
    """å¼‚æ­¥æ‰§è¡Œå¯ä¿¡åˆ†æ"""
    try:
        logger.info(f"å¼€å§‹å¼‚æ­¥å¯ä¿¡åˆ†æ: {completed_step}")
        
        # è·å–å½“å‰æ­¥éª¤ä¿¡æ¯
        current_step = {
            "title": completed_step,
            "content": plan_data.step_details.get(completed_step, ""),
            "status": "completed"
        }
        
        # è·å–æ‰€æœ‰å·²å®Œæˆçš„æ­¥éª¤
        all_completed_steps = []
        for step, status in plan_data.step_statuses.items():
            if status == 'completed':
                all_completed_steps.append({
                    "title": step,
                    "content": plan_data.step_details.get(step, ""),
                    "status": status
                })
        
        # è·å–å·¥å…·äº‹ä»¶ï¼ˆä»step_tool_callsä¸­æå–ï¼‰
        tool_events = []
        if hasattr(plan_data, 'step_tool_calls'):
            for step, tool_calls in plan_data.step_tool_calls.items():
                if step == completed_step:  # åªåˆ†æå½“å‰æ­¥éª¤çš„å·¥å…·è°ƒç”¨
                    for tool_call in tool_calls:
                        tool_events.append({
                            "tool_name": tool_call.get("tool_name", ""),
                            "tool_args": tool_call.get("tool_args", ""),
                            "timestamp": tool_call.get("timestamp", "")
                        })
        
        # è°ƒç”¨å¯ä¿¡åˆ†æå™¨ï¼ˆåœ¨å¼‚æ­¥ä»»åŠ¡ä¸­æ‰§è¡Œï¼‰
        credibility_result = await credibility_analyzer.analyze_step_credibility(
            current_step, all_completed_steps, tool_events
        )
        
        if credibility_result:
            # æ ¼å¼åŒ–å¯ä¿¡åˆ†ææ¶ˆæ¯
            # è®¡ç®—æ­¥éª¤ç´¢å¼•
            try:
                step_index = list(plan_data.steps).index(completed_step) if hasattr(plan_data, 'steps') else None
            except ValueError:
                step_index = None
            credibility_message = credibility_analyzer.format_credibility_message(
                credibility_result, completed_step, step_index
            )
            
            # å°†å¯ä¿¡åˆ†ææ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—
            if plan_queue is not None:
                await plan_queue.put(credibility_message)
                try:
                    import json as _json
                    payload_len = len(_json.dumps(credibility_message, ensure_ascii=False))
                except Exception:
                    payload_len = -1
                logger.info(f"å¼‚æ­¥å¯ä¿¡åˆ†æå®Œæˆï¼Œå·²æ¨é€åˆ°é˜Ÿåˆ— step={completed_step}, bytes~={payload_len}")
        else:
            logger.info(f"å¼‚æ­¥å¯ä¿¡åˆ†ææ— ç»“æœ: {completed_step}")
        
    except Exception as e:
        logger.error(f"å¼‚æ­¥å¯ä¿¡åˆ†æå¤±è´¥: {e}", exc_info=True)

async def _check_and_continue_next_step(plan_queue, plan_data: Plan):
    """æ£€æŸ¥å¹¶ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªæ­¥éª¤"""
    try:
        logger.info(f"æ£€æŸ¥ä¸‹ä¸€æ­¥éª¤ï¼Œå½“å‰è®¡åˆ’çŠ¶æ€: {plan_data.step_statuses}")
        
        # è·å–æ‰€æœ‰å¯æ‰§è¡Œçš„æ­¥éª¤
        ready_steps = plan_data.get_ready_steps()
        logger.info(f"æ‰¾åˆ°å¯æ‰§è¡Œçš„æ­¥éª¤: {ready_steps}")
        
        if ready_steps:
            logger.info(f"å‘ç° {len(ready_steps)} ä¸ªå¯æ‰§è¡Œæ­¥éª¤ï¼Œä½†ç­‰å¾…ä¸»å¾ªç¯è‡ªç„¶å¤„ç†")
            # ä¸ç«‹å³æ ‡è®°æ­¥éª¤ä¸ºè¿›è¡Œä¸­ï¼Œè®©ä¸»å¾ªç¯è‡ªç„¶å¤„ç†
            # è¿™æ ·å¯ä»¥é¿å…å¹¶å‘æ‰§è¡Œæ—¶çš„çŠ¶æ€å†²çª
        else:
            logger.info("æ²¡æœ‰æ‰¾åˆ°å¯æ‰§è¡Œçš„æ­¥éª¤ï¼Œè®¡åˆ’å¯èƒ½å·²å®Œæˆæˆ–é˜»å¡")
            
    except Exception as e:
        logger.error(f"æ£€æŸ¥ä¸‹ä¸€æ­¥éª¤å¤±è´¥: {e}", exc_info=True)

async def append_create_plan(data: Any):
    """
    å°†æ•°æ®è¿½åŠ å†™å…¥LOGS_PATHä¸‹çš„plan.logæ–‡ä»¶ï¼Œå¹¶å°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—ä»¥å‘é€ç»™å®¢æˆ·ç«¯

    Args:
        data: è¦å†™å…¥çš„æ•°æ®ï¼ˆæ”¯æŒå­—å…¸ã€åˆ—è¡¨ç­‰å¯JSONåºåˆ—åŒ–çš„ç±»å‹ï¼‰
    """
    try:
        # ä½¿ç”¨LOGS_PATHæ„å»ºæ–‡ä»¶è·¯å¾„
        file_path = Path(LOGS_PATH) / "plan.log"

        # å¤„ç†Planå¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„dict
        if isinstance(data, Plan):
            plan_dict = {
                "title": data.title if hasattr(data, 'title') else "",
                "steps": data.steps if hasattr(data, 'steps') else [],
                "step_files": data.step_files if hasattr(data, 'step_files') else {},
                "step_statuses": data.step_statuses if hasattr(data, 'step_statuses') else {},
                "step_notes": data.step_notes if hasattr(data, 'step_notes') else {},
                "step_details": data.step_details if hasattr(data, 'step_details') else {},
                "step_tool_calls": data.step_tool_calls if hasattr(data, 'step_tool_calls') else {},
                "dependencies": {str(k): v for k, v in data.dependencies.items()} if hasattr(data,
                                                                                             'dependencies') else {},
                "progress": data.get_progress() if hasattr(data, 'get_progress') and callable(
                    data.get_progress) else {},
                "result": data.get_plan_result() if hasattr(data, 'get_plan_result') and callable(
                    data.get_plan_result) else ""
            }
            logger.info(f"step_files:{data.step_files}")

            # logger.info(f"Planå¯¹è±¡å·²è½¬æ¢ä¸ºå­—å…¸: {plan_dict}")
            data = plan_dict
        # å¤„ç†å·¥å…·äº‹ä»¶æ•°æ®
        elif isinstance(data, dict) and data.get("event_type") in ["tool_start", "tool_complete", "tool_error"]:
            # åœ¨æ¨é€å‰ï¼Œå°†äº‹ä»¶ä¸­çš„æ–‡ä»¶ç³»ç»Ÿè·¯å¾„æ”¹å†™ä¸ºå¯è®¿é—®çš„ URL
            data = _rewrite_paths_in_payload(data)
            logger.info(f"Tool event: {data.get('event_type')} for {data.get('tool_name')}")

        # å‡†å¤‡å†™å…¥å†…å®¹ï¼ˆè‡ªåŠ¨å¤„ç†ä¸åŒç±»å‹ï¼‰
        if isinstance(data, (dict, list)):
            try:
                content = json.dumps(data, ensure_ascii=False, indent=2) + "\n"
            except TypeError as e:
                logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•è½¬æ¢å¯¹è±¡: {e}", exc_info=True)
                # å°è¯•å°†å¤æ‚å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if isinstance(data, dict):
                    serializable_data = {k: str(v) for k, v in data.items()}
                elif isinstance(data, list):
                    serializable_data = [
                        str(item) if not isinstance(item, (dict, list, str, int, float, bool, type(None))) else item for
                        item in data]
                content = json.dumps(serializable_data, ensure_ascii=False, indent=2) + "\n"
        else:
            content = str(data) + "\n"

        # è®°å½•åºåˆ—åŒ–åçš„å†…å®¹åˆ°æ—¥å¿—
        # logger.info(f"åºåˆ—åŒ–åçš„Planæ•°æ®: {content.strip()}")

        # è¿½åŠ å†™å…¥æ–‡ä»¶ï¼ˆè‡ªåŠ¨åˆ›å»ºæ–‡ä»¶ï¼‰
        with open(file_path, mode='a', encoding='utf-8') as f:
            f.write(content)

        # å°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—ä»¥ä¾¿æµå¼å‘é€ - ä½¿ç”¨run_coroutine_threadsafe
        global plan_queue, main_loop, analyzed_steps
        if plan_queue is not None and main_loop is not None:
            # ç¡®ä¿é˜Ÿåˆ—ä¸­çš„æ•°æ®æ˜¯å¯JSONåºåˆ—åŒ–çš„
            if isinstance(data, Plan):
                # å·²ç»åœ¨ä¸Šé¢è½¬æ¢è¿‡äº†
                asyncio.run_coroutine_threadsafe(plan_queue.put(plan_dict), main_loop)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å®Œæˆçš„æ­¥éª¤ï¼Œè§¦å‘å¯ä¿¡åˆ†æ
                if hasattr(data, 'step_statuses'):
                    logger.info(f"Planæ­¥éª¤çŠ¶æ€: {data.step_statuses}")
                    for step, status in data.step_statuses.items():
                        logger.info(f"æ£€æŸ¥æ­¥éª¤: {step}, çŠ¶æ€: {status}, å·²åˆ†æ: {step in analyzed_steps}")
                        if status == 'completed' and step not in analyzed_steps:
                            # æ ‡è®°ä¸ºå·²åˆ†æ
                            analyzed_steps.add(step)
                            # å¼‚æ­¥è§¦å‘å¯ä¿¡åˆ†æ - ä½¿ç”¨run_coroutine_threadsafeé¿å…é˜»å¡
                            try:
                                # ä½¿ç”¨run_coroutine_threadsafeè°ƒç”¨å¼‚æ­¥å‡½æ•°
                                asyncio.run_coroutine_threadsafe(_trigger_credibility_analysis(plan_queue, data, step), main_loop)
                            except Exception as e:
                                logger.error(f"è§¦å‘å¯ä¿¡åˆ†æå¤±è´¥: {e}", exc_info=True)
                            logger.info(f"è§¦å‘å¯ä¿¡åˆ†æ: {step}")
            else:
                asyncio.run_coroutine_threadsafe(plan_queue.put(data), main_loop)

    except json.JSONDecodeError as e:
        logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}", exc_info=True)
    except IOError as e:
        logger.error(f"æ–‡ä»¶å†™å…¥å¤±è´¥: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"æœªçŸ¥é”™è¯¯: {e}", exc_info=True)


def validate_search_input(params: dict) -> dict | None:
    """
    éªŒè¯æœç´¢è¾“å…¥å‚æ•°
    Args:
        params: è¾“å…¥å‚æ•°å­—å…¸
    Returns:
        å¦‚æœéªŒè¯å¤±è´¥è¿”å›é”™è¯¯å“åº”ï¼ŒéªŒè¯é€šè¿‡è¿”å›None
    """
    if not (content := params.get('content')) or len(content) == 0:
        return {
            "contentType": "multi-modal",
            "content": [{"type": "text", "value": i18n.t('invalid_command')}],
            "promptSentences": []
        }
    return None


@searchRouter.post("/deep-research/search")
async def search(request: Request, params: Any = Body(None)):
    logger.info(f"=====params:{params}")

    # if not await session_manager.authority(request):
    #     raise HTTPException(status_code=403, detail="Forbidden")

    if result := validate_search_input(params):
        return result

    session_info = params.get("sessionInfo", {})
    plan_id = session_info.get("messageSerialNumber", "")
    if not plan_id:
        # é€€åŒ–æ–¹æ¡ˆï¼šä½¿ç”¨æ—¶é—´æˆ³ï¼Œå»ºè®®å‰ç«¯ä¼ ç¨³å®šID
        plan_id = f"plan_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"

    # è·å–æŸ¥è¯¢å†…å®¹
    content_array = params.get('content', [])
    query_content = content_array[0]['value'] if content_array and isinstance(
        content_array, list) and len(content_array) > 0 and 'value' in content_array[0] else ""

    # è§„åˆ’æ¯ä¸ª plan çš„æŒä¹…åŒ–æ–‡ä»¶
    plan_log_path = os.path.join(LOGS_PATH, f"{plan_id}.log")
    plan_final_path = os.path.join(LOGS_PATH, f"{plan_id}.final.json")

    # æ„é€ è·¯å¾„ï¼š/xxx/xxx/work_space/work_space_æ—¶é—´æˆ³
    # åœ¨å‡½æ•°å¤–éƒ¨ç”Ÿæˆï¼Œç¡®ä¿RecordGeneratorå’Œgenerator_funcä½¿ç”¨ç›¸åŒè·¯å¾„
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
    work_space_path_time = os.path.join(work_space_path, f'work_space_{timestamp}')
    print(f"work_space_path_time:{work_space_path_time}")
    os.makedirs(work_space_path_time, exist_ok=True)
    
    # å°†å·¥ä½œç©ºé—´è·¯å¾„å­˜å‚¨åˆ°ç¯å¢ƒå˜é‡ï¼Œä¾›RecordGeneratorä½¿ç”¨
    os.environ['WORKSPACE_PATH'] = work_space_path_time

    async def generator_func():
        # æ¸…ç©ºä¹‹å‰å¯èƒ½å­˜åœ¨çš„é˜Ÿåˆ—æ•°æ®å¹¶ä¿å­˜å½“å‰äº‹ä»¶å¾ªç¯
        plan_queue = asyncio.Queue()
        main_loop = asyncio.get_running_loop()

        # ä¿å­˜æœ€æ–°çš„planæ•°æ®ï¼ˆä»…éå·¥å…·äº‹ä»¶ï¼‰
        latest_plan = None
        # æœ¬æ¬¡ä¼šè¯å†…å·²è§¦å‘å¯ä¿¡åˆ†æçš„æ­¥éª¤é›†åˆï¼Œé¿å…é‡å¤åˆ†æ
        analyzed_steps_local = set()

        def append_create_plan_local(data: Any):
            """
            å°†æ•°æ®è¿½åŠ å†™å…¥LOGS_PATHä¸‹æŒ‰ plan_id çš„æ–‡ä»¶ï¼Œå¹¶å°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—ä»¥å‘é€ç»™å®¢æˆ·ç«¯

            Args:
                data: è¦å†™å…¥çš„æ•°æ®ï¼ˆæ”¯æŒå­—å…¸ã€åˆ—è¡¨ç­‰å¯JSONåºåˆ—åŒ–çš„ç±»å‹ï¼‰
            """
            try:
                # é’ˆå¯¹å½“å‰ plan çš„æ—¥å¿—æ–‡ä»¶
                file_path = Path(plan_log_path)

                # å¤„ç†Planå¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„dict
                if isinstance(data, Plan):
                    plan_obj = data
                    plan_dict = {
                        "title": plan_obj.title if hasattr(plan_obj, 'title') else "",
                        "steps": plan_obj.steps if hasattr(plan_obj, 'steps') else [],
                        "step_files": plan_obj.step_files if hasattr(plan_obj, 'step_files') else {},
                        "step_statuses": plan_obj.step_statuses if hasattr(plan_obj, 'step_statuses') else {},
                        "step_notes": plan_obj.step_notes if hasattr(plan_obj, 'step_notes') else {},
                        "step_details": plan_obj.step_details if hasattr(plan_obj, 'step_details') else {},
                        "step_tool_calls": plan_obj.step_tool_calls if hasattr(plan_obj, 'step_tool_calls') else {},
                        "dependencies": {str(k): v for k, v in plan_obj.dependencies.items()} if hasattr(plan_obj,
                                                                                                     'dependencies') else {},
                        "progress": plan_obj.get_progress() if hasattr(plan_obj, 'get_progress') and callable(
                            data.get_progress) else {},
                        "result": plan_obj.get_plan_result() if hasattr(plan_obj, 'get_plan_result') and callable(
                            data.get_plan_result) else ""
                    }
                    logger.info(f"step_files:{plan_obj.step_files}")

                    # logger.info(f"Planå¯¹è±¡å·²è½¬æ¢ä¸ºå­—å…¸: {plan_dict}")
                    data = plan_dict

                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å®Œæˆçš„æ­¥éª¤ï¼Œè§¦å‘å¯ä¿¡åˆ†æï¼ˆä»…å¯¹å½“å‰ä¼šè¯å†…æœªåˆ†æçš„æ­¥éª¤è§¦å‘ä¸€æ¬¡ï¼‰
                    try:
                        if hasattr(plan_obj, 'step_statuses'):
                            for step, status in plan_obj.step_statuses.items():
                                if status == 'completed' and step not in analyzed_steps_local:
                                    analyzed_steps_local.add(step)
                                    # å¼‚æ­¥è§¦å‘å¯ä¿¡åˆ†æ - ä½¿ç”¨run_coroutine_threadsafeé¿å…é˜»å¡
                                    try:
                                        # ä½¿ç”¨run_coroutine_threadsafeè°ƒç”¨å¼‚æ­¥å‡½æ•°
                                        asyncio.run_coroutine_threadsafe(_trigger_credibility_analysis(plan_queue, plan_obj, step), main_loop)
                                    except Exception as e:
                                        logger.error(f"è§¦å‘å¯ä¿¡åˆ†æå¤±è´¥: {e}", exc_info=True)
                                    logger.info(f"è§¦å‘å¯ä¿¡åˆ†æ(æœ¬åœ°é˜Ÿåˆ—): {step}")
                    except Exception as _e:
                        logger.error(f"è§¦å‘å¯ä¿¡åˆ†æå¤±è´¥: {_e}", exc_info=True)
                # å¤„ç†å·¥å…·äº‹ä»¶æ•°æ®
                elif isinstance(data, dict) and data.get("event_type") in ["tool_start", "tool_complete", "tool_error"]:
                    # å¯¹å·¥å…·äº‹ä»¶è¿›è¡Œè·¯å¾„æ”¹å†™ï¼ˆåŒ…æ‹¬åµŒå¥— plan.processed_result.file_path ç­‰ï¼‰
                    try:
                        data = _rewrite_paths_in_payload(data)
                    except Exception:
                        pass
                    logger.info(f"Tool event received: {data.get('event_type')} for {data.get('tool_name')} at step {data.get('step_index')}")

                # å‡†å¤‡å†™å…¥å†…å®¹ï¼ˆè‡ªåŠ¨å¤„ç†ä¸åŒç±»å‹ï¼‰
                if isinstance(data, (dict, list)):
                    try:
                        content = json.dumps(data, ensure_ascii=False, indent=2) + "\n"
                    except TypeError as e:
                        logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•è½¬æ¢å¯¹è±¡: {e}", exc_info=True)
                        # å°è¯•å°†å¤æ‚å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        if isinstance(data, dict):
                            serializable_data = {k: str(v) for k, v in data.items()}
                        elif isinstance(data, list):
                            serializable_data = [str(item) if not isinstance(item, (
                            dict, list, str, int, float, bool, type(None))) else item for item in data]
                        content = json.dumps(serializable_data, ensure_ascii=False, indent=2) + "\n"
                else:
                    content = str(data) + "\n"

                # è¿½åŠ å†™å…¥å½“å‰ plan çš„æ—¥å¿—
                with open(file_path, mode='a', encoding='utf-8') as f:
                    f.write(content)

                # å¦‚æœåŒ…å«æœ€ç»ˆç»“æœï¼Œå•ç‹¬è½ç›˜ final æ–‡ä»¶
                try:
                    if isinstance(data, dict) and data.get("result"):
                        with open(plan_final_path, mode='w', encoding='utf-8') as ff:
                            ff.write(json.dumps(data, ensure_ascii=False, indent=2))
                except Exception as _:
                    pass

                # å°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—ä»¥ä¾¿æµå¼å‘é€
                if plan_queue is not None and main_loop is not None:
                    if isinstance(data, Plan):
                        logger.info(f"Pushing Plan data to queue for plan_id: {plan_id}")
                        asyncio.run_coroutine_threadsafe(plan_queue.put(plan_dict), main_loop)
                    else:
                        # éPlanï¼ˆåŒ…æ‹¬å·¥å…·äº‹ä»¶ï¼‰åœ¨å…¥é˜Ÿå‰å†åšä¸€æ¬¡è·¯å¾„æ”¹å†™å…œåº•
                        safe_data = _rewrite_paths_in_payload(data)
                        logger.info(f"Pushing non-Plan data to queue: {type(data).__name__} for plan_id: {plan_id}")
                        asyncio.run_coroutine_threadsafe(plan_queue.put(safe_data), main_loop)
                else:
                    logger.warning(f"Queue or main_loop is None, cannot push data for plan_id: {plan_id}")

            except json.JSONDecodeError as e:
                logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}", exc_info=True)
            except IOError as e:
                logger.error(f"æ–‡ä»¶å†™å…¥å¤±è´¥: {e}", exc_info=True)
            except Exception as e:
                logger.error(f"æœªçŸ¥é”™è¯¯: {e}", exc_info=True)

        # å¦‚æœå·²å­˜åœ¨æœ€ç»ˆç»“æœï¼Œä¸”å½“å‰ä¸åœ¨è¿è¡Œï¼Œç›´æ¥å›æ”¾å¹¶ç»“æŸ
        try:
            if not TaskManager.is_running(plan_id) and os.path.exists(plan_final_path):
                with open(plan_final_path, 'r', encoding='utf-8') as rf:
                    final_obj = json.load(rf)
                final_obj = dict(final_obj)
                final_obj["status_text"] = "æ‰§è¡Œå®Œæˆ"
                yield {"plan": final_obj}
                return
            # è‹¥å­˜åœ¨å†å²æ—¥å¿—ä¸”ä¸åœ¨è¿è¡Œï¼Œå›æ”¾æ—¥å¿—åç»“æŸ
            if not TaskManager.is_running(plan_id) and os.path.exists(plan_log_path):
                with open(plan_log_path, 'r', encoding='utf-8') as lf:
                    for line in lf:
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            obj = json.loads(line)
                        except Exception:
                            continue
                        # å·¥å…·äº‹ä»¶é€ä¼ 
                        if isinstance(obj, dict) and obj.get("event_type") in ["tool_start", "tool_complete", "tool_error"]:
                            yield {"plan": obj}
                        else:
                            yield {"plan": obj}
                return
        except Exception as _:
            # å›æ”¾å¤±è´¥æ—¶å¿½ç•¥ï¼Œç»§ç»­åç»­é€»è¾‘
            pass

        # åœ¨å­çº¿ç¨‹ä¸­æ‰§è¡ŒCoSightä»»åŠ¡ï¼ˆè‹¥æœªåœ¨è¿è¡Œï¼‰
        def run_manus():
            try:
                # é¿å…è¿›ç¨‹çº§ç¯å¢ƒå˜é‡è¢«å¹¶å‘è¦†ç›–ï¼Œä¼˜å…ˆé€šè¿‡å‚æ•°ä¼ é€’
                os.environ['WORKSPACE_PATH'] = work_space_path_time
                
                # å…ˆè®¢é˜…äº‹ä»¶ï¼Œå…³è”plan_id - ç¡®ä¿åœ¨CoSightåˆå§‹åŒ–ä¹‹å‰å®Œæˆè®¢é˜…
                logger.info(f"Subscribing to events for plan_id: {plan_id}")
                plan_report_event_manager.subscribe("plan_created", plan_id, append_create_plan_local)
                plan_report_event_manager.subscribe("plan_updated", plan_id, append_create_plan_local)
                plan_report_event_manager.subscribe("plan_process", plan_id, append_create_plan_local)
                plan_report_event_manager.subscribe("plan_result", plan_id, append_create_plan_local)
                plan_report_event_manager.subscribe("tool_event", plan_id, append_create_plan_local)
                logger.info(f"Event subscription completed for plan_id: {plan_id}")

                # åˆå§‹åŒ–CoSightå¹¶ä¼ å…¥plan_id
                logger.info(f"llm is {llm_for_plan.model}, {llm_for_plan.base_url}, {llm_for_plan.api_key}")
                cosight = CoSight(
                    llm_for_plan,
                    llm_for_act,
                    llm_for_tool,
                    llm_for_vision,
                    work_space_path=work_space_path_time,
                    message_uuid = plan_id
                )
                result = cosight.execute(query_content)
                logger.info(f"final result is {result}")

            except Exception as e:
                logger.error(f"CoSightæ‰§è¡Œé”™è¯¯: {e}", exc_info=True)
            finally:
                # æ‰§è¡Œå®Œæˆåå–æ¶ˆè®¢é˜…
                plan_report_event_manager.unsubscribe("plan_created", plan_id, append_create_plan_local)
                plan_report_event_manager.unsubscribe("plan_updated", plan_id, append_create_plan_local)
                plan_report_event_manager.unsubscribe("plan_process", plan_id, append_create_plan_local)
                plan_report_event_manager.unsubscribe("plan_result", plan_id, append_create_plan_local)
                plan_report_event_manager.unsubscribe("tool_event", plan_id, append_create_plan_local)
                # æ¸…ç†TaskManagerä¸­çš„æ˜ å°„ä¸è¿è¡Œæ€
                TaskManager.mark_completed(plan_id)
                TaskManager.remove_plan(plan_id)

        # å¹‚ç­‰ï¼šè‹¥å·²åœ¨è¿è¡Œï¼Œä»…è®¢é˜…å¹¶å¤ç”¨å·²æœ‰æ‰§è¡Œï¼›å¦åˆ™å¯åŠ¨æ–°æ‰§è¡Œ
        if TaskManager.is_running(plan_id):
            # ä»…è®¢é˜…ï¼Œå°†å½“å‰è¯·æ±‚çš„é˜Ÿåˆ—ä½œä¸ºæ–°çš„ç›‘å¬è€…
            logger.info(f"Task already running for plan_id: {plan_id}, subscribing to events")
            plan_report_event_manager.subscribe("plan_created", plan_id, append_create_plan_local)
            plan_report_event_manager.subscribe("plan_updated", plan_id, append_create_plan_local)
            plan_report_event_manager.subscribe("plan_process", plan_id, append_create_plan_local)
            plan_report_event_manager.subscribe("plan_result", plan_id, append_create_plan_local)
            plan_report_event_manager.subscribe("tool_event", plan_id, append_create_plan_local)
        else:
            TaskManager.mark_running(plan_id)
            logger.info(f"Starting new task for plan_id: {plan_id}")
            import threading
            thread = threading.Thread(target=run_manus)
            thread.daemon = True
            thread.start()

        # æŒç»­ä»é˜Ÿåˆ—è·å–æ•°æ®å¹¶äº§ç”Ÿå“åº”
        last_plan_fingerprint = None  # é¿å…ç›¸åŒè®¡åˆ’é‡å¤å‘é€
        emitted_credibility_keys = set()  # é¿å…åŒä¸€æ­¥éª¤çš„å¯ä¿¡åˆ†æé‡å¤å‘é€
        while True:
            try:
                # ç­‰å¾…é˜Ÿåˆ—ä¸­çš„æ•°æ®ï¼Œè®¾ç½®è¶…æ—¶é˜²æ­¢æ— é™ç­‰å¾…
                data = await asyncio.wait_for(plan_queue.get(), timeout=60.0)
                # logger.info(f"queue_data:{data}")

                # è‹¥ä¸ºå¯ä¿¡åˆ†æäº‹ä»¶ï¼Œç›´æ¥é€ä¼ ï¼Œé¿å…è¢«åŒ…è£…ä¸º plan
                if isinstance(data, dict) and data.get("type") in ("credibility-analysis", "lui-message-credibility-analysis"):
                    try:
                        cred_key = f"{data.get('type')}|{data.get('stepTitle')}|{data.get('stepIndex')}"
                    except Exception:
                        cred_key = None
                    if cred_key is None or cred_key not in emitted_credibility_keys:
                        if cred_key is not None:
                            emitted_credibility_keys.add(cred_key)
                        yield data
                    continue

                # å…¼å®¹ï¼šå¯ä¿¡åˆ†æè¢«åŒ…è£¹åœ¨ plan ä¸­
                if (
                    isinstance(data, dict)
                    and isinstance(data.get("plan"), dict)
                    and data["plan"].get("type") in ("credibility-analysis", "lui-message-credibility-analysis")
                ):
                    yield data["plan"]
                    continue

                # å·¥å…·äº‹ä»¶ï¼ˆè£¸ dictï¼‰ï¼Œç›´æ¥é€ä¼ ä¸”ä¸æ›´æ–°latest_planï¼ˆé¿å…ä¿æ´»é‡å¤å‘é€å·¥å…·äº‹ä»¶ï¼‰
                if isinstance(data, dict) and data.get("event_type") in ["tool_start", "tool_complete", "tool_error"]:
                    # å·¥å…·äº‹ä»¶ç›´æ¥é€ä¼ ï¼Œä¸åŒ…è£…åœ¨planä¸­
                    yield data
                    continue

                # è®¡åˆ’ç»“æœå®Œæˆ
                if isinstance(data, dict) and "result" in data and data['result']:
                    latest_plan = data
                    completed_plan = dict(latest_plan)
                    completed_plan["statusText"] = "æ‰§è¡Œå®Œæˆ"
                    yield {"plan": completed_plan}
                    break

                # æ›´æ–°æœ€æ–°planæ•°æ®ï¼ˆéå·¥å…·äº‹ä»¶ï¼‰
                latest_plan = data
                running_plan = dict(latest_plan) if isinstance(latest_plan, dict) else latest_plan
                if isinstance(running_plan, dict):
                    running_plan["statusText"] = "æ­£åœ¨æ‰§è¡Œä¸­"
                # å‘é€å®Œæ•´çš„planï¼ˆå»é‡ï¼‰
                try:
                    import hashlib as _hashlib
                    plan_fp = _hashlib.md5(json.dumps(running_plan, ensure_ascii=False, sort_keys=True).encode('utf-8')).hexdigest() if isinstance(running_plan, dict) else None
                except Exception:
                    plan_fp = None
                if plan_fp is None or plan_fp != last_plan_fingerprint:
                    last_plan_fingerprint = plan_fp
                    yield {"plan": running_plan}

            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œä»…å‘é€ä¿æ´»çŠ¶æ€ã€‚è‹¥æœ‰æœ€æ–°éå·¥å…·è®¡åˆ’ï¼Œåˆ™åŸºäºå…¶å‘é€ï¼›å¦åˆ™å‘é€é»˜è®¤ç­‰å¾…è®¡åˆ’
                if latest_plan and isinstance(latest_plan, dict):
                    waiting_plan = dict(latest_plan)
                    waiting_plan["statusText"] = "ç­‰å¾…è®¡åˆ’æ›´æ–°..."
                    try:
                        import hashlib as _hashlib
                        plan_fp = _hashlib.md5(json.dumps(waiting_plan, ensure_ascii=False, sort_keys=True).encode('utf-8')).hexdigest()
                    except Exception:
                        plan_fp = None
                    if plan_fp is None or plan_fp != last_plan_fingerprint:
                        last_plan_fingerprint = plan_fp
                        yield {"plan": waiting_plan}
                else:
                    contains_chinese = any('\u4e00' <= c <= '\u9fff' for c in query_content)
                    title = "ç­‰å¾…ä»»åŠ¡æ‰§è¡Œ" if contains_chinese else "Waiting for task execution"
                    default_plan = {"title": title, "statusText": "ç­‰å¾…è®¡åˆ’æ›´æ–°...", "steps": []}
                    try:
                        import hashlib as _hashlib
                        plan_fp = _hashlib.md5(json.dumps(default_plan, ensure_ascii=False, sort_keys=True).encode('utf-8')).hexdigest()
                    except Exception:
                        plan_fp = None
                    if plan_fp is None or plan_fp != last_plan_fingerprint:
                        last_plan_fingerprint = plan_fp
                        yield {"plan": default_plan}
            except Exception as e:
                logger.error(f"ç”Ÿæˆå“åº”é”™è¯¯: {e}", exc_info=True)
                # å‘é€é”™è¯¯çŠ¶æ€ï¼Œä½†ä¿ç•™æœ€æ–°plan
                if latest_plan and isinstance(latest_plan, dict):
                    error_plan = dict(latest_plan)
                    error_plan["statusText"] = f"ç”Ÿæˆå“åº”å‡ºé”™: {str(e)}"
                    yield {"plan": error_plan}
                else:
                    yield {"plan": {"title": "ä»»åŠ¡å‡ºé”™", "statusText": f"ç”Ÿæˆå“åº”å‡ºé”™: {str(e)}", "steps": []}}
                break

    async def generate_stream_response(generator_func, params):
        try:
            async for response_data in generator_func():
                # å¯ä¿¡åˆ†æäº‹ä»¶ä¼˜å…ˆåŒ¹é…
                if isinstance(response_data, dict) and response_data.get("type") in ("credibility-analysis", "lui-message-credibility-analysis"):
                    try:
                        logger.info("å‘é€å¯ä¿¡åˆ†ææ¶ˆæ¯åˆ°å‰ç«¯")
                    except Exception:
                        pass
                    response_json = {
                        "contentType": "lui-message-credibility-analysis",
                        "sessionInfo": params.get("sessionInfo", {}),
                        "code": 0,
                        "message": "ok",
                        "task": "credibility_analysis",
                        "changeType": "append",
                        "content": response_data
                    }
                # å·¥å…·äº‹ä»¶ï¼ˆç›´æ¥é€ä¼ ï¼‰ï¼Œæ³¨æ„ç©ºå€¼åˆ¤æ–­
                elif (
                    isinstance(response_data, dict)
                    and response_data.get("event_type") in ["tool_start", "tool_complete", "tool_error"]
                ):
                    try:
                        logger.info("å‘é€å·¥å…·äº‹ä»¶åˆ°å‰ç«¯")
                    except Exception:
                        pass
                    response_json = {
                        "contentType": "lui-message-tool-event",
                        "sessionInfo": params.get("sessionInfo", {}),
                        "code": 0,
                        "message": "ok",
                        "task": "tool_event",
                        "changeType": "append",
                        "content": response_data
                    }
                # å…¼å®¹ï¼šè‹¥åŒ…è£¹åœ¨ plan ä¸­çš„ä¹Ÿæ˜¯å¯ä¿¡åˆ†æï¼Œåˆ™æ‹†åŒ…æˆå¯ä¿¡åˆ†ææ¶ˆæ¯
                elif (
                    isinstance(response_data, dict)
                    and isinstance(response_data.get("plan"), dict)
                    and response_data["plan"].get("type") in ("credibility-analysis", "lui-message-credibility-analysis")
                ):
                    try:
                        logger.info("å‘é€planå†…å¯ä¿¡åˆ†ææ¶ˆæ¯åˆ°å‰ç«¯")
                    except Exception:
                        pass
                    response_json = {
                        "contentType": "lui-message-credibility-analysis",
                        "sessionInfo": params.get("sessionInfo", {}),
                        "code": 0,
                        "message": "ok",
                        "task": "credibility_analysis",
                        "changeType": "append",
                        "content": response_data["plan"]
                    }
                elif isinstance(response_data, dict) and "plan" in response_data:
                    # è®¡åˆ’äº‹ä»¶ä½¿ç”¨åŸæœ‰çš„contentType
                    try:
                        logger.info("å‘é€è®¡åˆ’è¿›åº¦åˆ°å‰ç«¯")
                    except Exception:
                        pass
                    response_json = {
                        "contentType": "lui-message-manus-step",
                        "sessionInfo": params.get("sessionInfo", {}),
                        "code": 0,
                        "message": "ok",
                        "task": "chat",
                        "changeType": "replace",
                        "content": response_data["plan"]  # ç›´æ¥ä½¿ç”¨planæ•°æ®ä½œä¸ºcontent
                    }
                else:
                    # å…¶ä»–ç±»å‹çš„æ•°æ®ï¼Œå¯èƒ½æ˜¯ç›´æ¥çš„Planå¯¹è±¡æˆ–å…¶ä»–æ ¼å¼
                    try:
                        logger.info("å‘é€å…œåº•æ¶ˆæ¯åˆ°å‰ç«¯")
                    except Exception:
                        pass
                    response_json = {
                        "contentType": "lui-message-manus-step",
                        "sessionInfo": params.get("sessionInfo", {}),
                        "code": 0,
                        "message": "ok",
                        "task": "chat",
                        "changeType": "replace",
                        "content": response_data  # ç›´æ¥ä½¿ç”¨æ•°æ®ä½œä¸ºcontent
                    }

                yield json.dumps(response_json, ensure_ascii=False).encode('utf-8') + b'\n'
                await asyncio.sleep(0)

        except Exception as exc:
            error_msg = "ç”Ÿæˆå›å¤æ—¶å‘ç”Ÿé”™è¯¯ã€‚"
            logger.exception(error_msg)
            error_response = json.dumps({
                "contentType": "lui-message-manus-step",
                "content": {"intro": error_msg, "steps": []},
                "sessionInfo": params.get("sessionInfo", {}),
                "code": 1,
                "message": "error",
                "task": "chat",
                "changeType": "replace"
            }, ensure_ascii=False).encode('utf-8') + b'\n'
            yield error_response

    async def RecordGenerator(workspace_path=None):
        """ä¸¤ç§æ¨¡å¼çš„ç”Ÿæˆå™¨ï¼š
        - è®°å½•æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼šå°† generate_stream_response äº§ç”Ÿçš„æ¯ä¸€è¡Œå†™å…¥å½“å‰ WORKSPACE_PATH ä¸‹çš„ replay.jsonï¼ŒåŒæ—¶æ­£å¸¸å‘å‰ç«¯ yield
        - å›æ”¾æ¨¡å¼ï¼šä» replay.json è¯»å–å†å²æ•°æ®ï¼ŒæŒ‰è¡Œæ¯ 2 ç§’ yield ä¸€æ¬¡
        
        å›æ”¾æ¨¡å¼è§¦å‘æ¡ä»¶ï¼šparams ä¸­å­˜åœ¨é”® 'replay' ä¸”ä¸ºçœŸå€¼
        """
        try:
            replay_mode = bool(params.get("replay", False)) if isinstance(params, dict) else False
        except Exception:
            replay_mode = False

        # è·å–å½“å‰ä¼šè¯çš„ workspace ç›®å½•ï¼ˆä¼˜å…ˆä½¿ç”¨è°ƒç”¨æ–¹æ˜¾å¼ä¼ å…¥çš„é‡æ”¾ç›®å½•ï¼‰
        explicit_workspace = None
        try:
            if isinstance(params, dict):
                explicit_workspace = params.get('replayWorkspace')
        except Exception:
            explicit_workspace = None
        
        # å¯¹äºæ–°ä»»åŠ¡ï¼Œä½¿ç”¨ä¸ run_manus ç›¸åŒçš„å·¥ä½œç©ºé—´è·¯å¾„
        if not replay_mode and not explicit_workspace:
            # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„å·¥ä½œç©ºé—´è·¯å¾„ï¼ˆç”±generator_funcè®¾ç½®ï¼‰
            try:
                curr_workspace = os.environ.get('WORKSPACE_PATH')
            except Exception:
                curr_workspace = None
            
            # å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ï¼Œåˆ™ä½¿ç”¨ä¼ å…¥çš„å·¥ä½œç©ºé—´è·¯å¾„
            if not curr_workspace and workspace_path:
                curr_workspace = workspace_path
            
            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œåˆ™ç”Ÿæˆæ–°çš„æ—¶é—´æˆ³å·¥ä½œç©ºé—´è·¯å¾„
            if not curr_workspace:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                curr_workspace = os.path.join(work_space_path, f'work_space_{timestamp}')
        elif explicit_workspace and isinstance(explicit_workspace, str) and len(explicit_workspace) > 0:
            curr_workspace = explicit_workspace
        else:
            try:
                curr_workspace = os.environ.get('WORKSPACE_PATH')
            except Exception:
                curr_workspace = None
            if not curr_workspace:
                curr_workspace = work_space_path

        replay_file_path = None
        if curr_workspace:
            try:
                os.makedirs(curr_workspace, exist_ok=True)
                replay_file_path = os.path.join(curr_workspace, 'replay.json')
            except Exception:
                replay_file_path = None

        if replay_mode:
            # å›æ”¾æ¨¡å¼ï¼šé€è¡Œè¯»å–å†å²è®°å½•
            try:
                print(f"Replay file path: {replay_file_path}")
                replay_file_path='work_space/work_space_20250926_194936_689374/replay.json'
                if replay_file_path and os.path.exists(replay_file_path):
                    with open(replay_file_path, 'r', encoding='utf-8') as rf:
                        for line in rf:
                            line = line.rstrip('\n')
                            if not line:
                                await asyncio.sleep(1)
                                continue
                            try:
                                yield line.encode('utf-8') + b'\n'
                            except Exception:
                                # å¦‚æœç¼–ç å¤±è´¥ï¼Œå¿½ç•¥è¯¥è¡Œ
                                pass
                            await asyncio.sleep(1)
                    return
                else:
                    # æ²¡æœ‰å†å²å›æ”¾æ–‡ä»¶ï¼Œè¾“å‡ºä¸€æ¡æç¤ºä¿¡æ¯
                    fallback = {
                        "contentType": "lui-message-manus-step",
                        "sessionInfo": params.get("sessionInfo", {}) if isinstance(params, dict) else {},
                        "code": 0,
                        "message": "no replay file",
                        "task": "chat",
                        "changeType": "replace",
                        "content": {"title": "å›æ”¾æ–‡ä»¶ä¸å­˜åœ¨", "steps": [], "statusText": "æ— å¯å›æ”¾å†…å®¹"}
                    }
                    yield json.dumps(fallback, ensure_ascii=False).encode('utf-8') + b'\n'
                    return
            except Exception as e:
                logger.error(f"å›æ”¾æ¨¡å¼å¤±è´¥: {e}", exc_info=True)
                # å›é€€åˆ°è®°å½•æ¨¡å¼
                replay_mode = False

        # è®°å½•æ¨¡å¼ï¼šåŒ…è£¹ç°æœ‰æµå¹¶å†™å…¥æ–‡ä»¶
        async for chunk in generate_stream_response(generator_func, params):
            try:
                if replay_file_path:
                    try:
                        # chunk ä¸º bytesï¼Œç›´æ¥è§£ç å¹¶æŒ‰è¡Œå†™å…¥
                        text = chunk.decode('utf-8')
                    except Exception:
                        try:
                            text = str(chunk)
                        except Exception:
                            text = ''
                    if text:
                        with open(replay_file_path, 'a', encoding='utf-8') as wf:
                            # ç»Ÿä¸€ç¡®ä¿æ¯æ¡è®°å½•ä»¥æ¢è¡Œç»“æŸ
                            if text.endswith('\n'):
                                wf.write(text)
                            else:
                                wf.write(text + '\n')
            except Exception as _e:
                logger.error(f"å†™å…¥å›æ”¾æ–‡ä»¶å¤±è´¥: {_e}", exc_info=True)

            yield chunk

    return StreamingResponse(
        RecordGenerator(work_space_path_time),
        media_type="application/json"
    )


@searchRouter.get("/search-results")
async def show_search_results(request: Request, query: str = "", tool: str = "", timestamp: str = ""):
    """
    å±•ç¤ºæœç´¢ç»“æœçš„å¯åµŒå…¥é¡µé¢
    
    Args:
        query: æœç´¢æŸ¥è¯¢å†…å®¹
        tool: æœç´¢å·¥å…·åç§°
        timestamp: æ—¶é—´æˆ³ï¼ˆç”¨äºé¿å…ç¼“å­˜ï¼‰
    """
    from fastapi.responses import HTMLResponse
    import urllib.parse
    
    # URLè§£ç æŸ¥è¯¢å†…å®¹
    decoded_query = urllib.parse.unquote(query) if query else "æœç´¢ç»“æœ"
    
    # ç”ŸæˆHTMLé¡µé¢
    html_content = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>æœç´¢ç»“æœ - {decoded_query}</title>
        <style>
            body {{
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                margin: 0;
                padding: 20px;
                background-color: #f5f5f5;
                line-height: 1.6;
            }}
            .container {{
                max-width: 800px;
                margin: 0 auto;
                background: white;
                border-radius: 8px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                overflow: hidden;
            }}
            .header {{
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 20px;
                text-align: center;
            }}
            .header h1 {{
                margin: 0;
                font-size: 24px;
                font-weight: 300;
            }}
            .search-info {{
                padding: 20px;
                border-bottom: 1px solid #eee;
            }}
            .search-query {{
                font-size: 18px;
                color: #333;
                margin-bottom: 10px;
            }}
            .search-tool {{
                color: #666;
                font-size: 14px;
            }}
            .content {{
                padding: 20px;
            }}
            .message {{
                text-align: center;
                color: #666;
                font-size: 16px;
                margin: 40px 0;
            }}
            .external-links {{
                margin-top: 30px;
            }}
            .external-links h3 {{
                color: #333;
                margin-bottom: 15px;
            }}
            .link-item {{
                background: #f8f9fa;
                border: 1px solid #e9ecef;
                border-radius: 6px;
                padding: 15px;
                margin-bottom: 10px;
                transition: all 0.2s ease;
            }}
            .link-item:hover {{
                background: #e9ecef;
                transform: translateY(-1px);
            }}
            .link-item a {{
                color: #007bff;
                text-decoration: none;
                font-weight: 500;
            }}
            .link-item a:hover {{
                text-decoration: underline;
            }}
            .link-description {{
                color: #666;
                font-size: 14px;
                margin-top: 5px;
            }}
            .footer {{
                background: #f8f9fa;
                padding: 15px 20px;
                text-align: center;
                color: #666;
                font-size: 12px;
                border-top: 1px solid #eee;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ” æœç´¢ç»“æœ</h1>
            </div>
            
            <div class="search-info">
                <div class="search-query">æœç´¢å†…å®¹ï¼š{decoded_query}</div>
                <div class="search-tool">æœç´¢å·¥å…·ï¼š{tool if tool else 'æœªçŸ¥'}</div>
            </div>
            
            <div class="content">
                <div class="message">
                    <p>ğŸ“‹ æœç´¢ç»“æœå·²ç”Ÿæˆï¼Œä½†ç”±äºå®‰å…¨é™åˆ¶ï¼Œæ— æ³•åœ¨æ­¤é¡µé¢ç›´æ¥åµŒå…¥æ˜¾ç¤ºã€‚</p>
                    <p>ğŸ’¡ æ‚¨å¯ä»¥åœ¨æ–°çª—å£ä¸­æ‰“å¼€ä»¥ä¸‹é“¾æ¥æŸ¥çœ‹è¯¦ç»†å†…å®¹ï¼š</p>
                </div>
                
                <div class="external-links">
                    <h3>ğŸ”— ç›¸å…³æœç´¢é“¾æ¥</h3>
                    <div class="link-item">
                        <a href="https://www.baidu.com/s?wd={urllib.parse.quote(decoded_query)}" target="_blank">
                            ğŸ” ç™¾åº¦æœç´¢ï¼š{decoded_query}
                        </a>
                        <div class="link-description">åœ¨ç™¾åº¦ä¸­æœç´¢ç›¸å…³å†…å®¹</div>
                    </div>
                    <div class="link-item">
                        <a href="https://www.google.com/search?q={urllib.parse.quote(decoded_query)}" target="_blank">
                            ğŸŒ Googleæœç´¢ï¼š{decoded_query}
                        </a>
                        <div class="link-description">åœ¨Googleä¸­æœç´¢ç›¸å…³å†…å®¹</div>
                    </div>
                    <div class="link-item">
                        <a href="https://zh.wikipedia.org/wiki/Special:Search?search={urllib.parse.quote(decoded_query)}" target="_blank">
                            ğŸ“š ç»´åŸºç™¾ç§‘ï¼š{decoded_query}
                        </a>
                        <div class="link-description">åœ¨ç»´åŸºç™¾ç§‘ä¸­æœç´¢ç›¸å…³å†…å®¹</div>
                    </div>
                </div>
            </div>
            
            <div class="footer">
                <p>Co-Sight æ™ºèƒ½æœç´¢ç³»ç»Ÿ | ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
        </div>
    </body>
    </html>
    """
    
    return HTMLResponse(content=html_content)
